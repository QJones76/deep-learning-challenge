{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat the processing steps to get the data to the same place. Then, play around with optimization by bucketing asking amount and \n",
    "\n",
    "# Import our dependencies\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_tuner as k\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Read the charity_data.csv from the provided cloud URL.\n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
    "\n",
    "# Do most basic processing outlined in instructions\n",
    "application_df = application_df.drop(columns=['EIN', 'NAME'])\n",
    "\n",
    "application_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Optimization Option 1: \n",
    "Firstly, I need to figure out what columns in the processed DataFrame are important. I can accomplish this with this code. Then I also want to add way more layers and nodes to my model for the best possible accuracy improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  \\\n",
       "0       1     5000              1                  True                 False   \n",
       "1       1   108590              1                 False                 False   \n",
       "2       1     5000              0                 False                 False   \n",
       "3       1     6692              1                 False                 False   \n",
       "4       1   142590              1                 False                 False   \n",
       "\n",
       "   APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  \\\n",
       "0                False                False                False   \n",
       "1                 True                False                False   \n",
       "2                False                False                 True   \n",
       "3                 True                False                False   \n",
       "4                 True                False                False   \n",
       "\n",
       "   APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  ORGANIZATION_Trust  \\\n",
       "0                False                False  ...               False   \n",
       "1                False                False  ...               False   \n",
       "2                False                False  ...               False   \n",
       "3                False                False  ...                True   \n",
       "4                False                False  ...                True   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0              False                   False                     False   \n",
       "1               True                   False                     False   \n",
       "2              False                   False                     False   \n",
       "3              False                    True                     False   \n",
       "4              False                   False                      True   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0               False             False                   False   \n",
       "1               False             False                   False   \n",
       "2               False             False                   False   \n",
       "3               False             False                   False   \n",
       "4               False             False                   False   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_Y  \n",
       "0            False              False                     False  \n",
       "1            False              False                     False  \n",
       "2            False              False                     False  \n",
       "3            False              False                     False  \n",
       "4            False              False                     False  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a coppy of the application dataframe\n",
    "important_df = application_df.copy()\n",
    "\n",
    "# Add the same application and classification cutoffs as before\n",
    "# Define application_cutoff\n",
    "application_cutoff = 500\n",
    "\n",
    "# Identify applications with counts below the cutoff\n",
    "application_types_to_replace = important_df['APPLICATION_TYPE'].value_counts()\n",
    "application_types_to_replace = application_types_to_replace[application_types_to_replace < application_cutoff].index.tolist()\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    important_df['APPLICATION_TYPE'] = important_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Define classificaiton_cutoff\n",
    "classification_cutoff = 1000\n",
    "\n",
    "# Identify classifications with counts below the cutoff\n",
    "classifications_to_replace = important_df['CLASSIFICATION'].value_counts()\n",
    "classifications_to_replace = classifications_to_replace[classifications_to_replace < classification_cutoff].index.tolist()\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    important_df['CLASSIFICATION'] = important_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "\n",
    "# List of columns with categorical data\n",
    "categorical_columns = [\n",
    "    'APPLICATION_TYPE', 'AFFILIATION', 'CLASSIFICATION', 'USE_CASE', 'ORGANIZATION',\n",
    "    'INCOME_AMT', 'SPECIAL_CONSIDERATIONS'\n",
    "]\n",
    "\n",
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "application_dummies = pd.get_dummies(important_df[categorical_columns], drop_first=True)\n",
    "\n",
    "# Add dummies to copy of DataFrame for model building\n",
    "important_df = pd.concat([important_df, application_dummies], axis=1)\n",
    "\n",
    "# Drop original non-numeric columns \n",
    "important_df = important_df.drop(columns=categorical_columns)\n",
    "\n",
    "# Check the proccessed DataFrame\n",
    "important_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "Accuracy: 0.7258\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.69      3196\n",
      "           1       0.72      0.79      0.75      3664\n",
      "\n",
      "    accuracy                           0.73      6860\n",
      "   macro avg       0.73      0.72      0.72      6860\n",
      "weighted avg       0.73      0.73      0.72      6860\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AFFILIATION_Independent</td>\n",
       "      <td>0.450664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ORGANIZATION_Trust</td>\n",
       "      <td>0.083658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CLASSIFICATION_C2100</td>\n",
       "      <td>0.055752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>APPLICATION_TYPE_T5</td>\n",
       "      <td>0.046338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APPLICATION_TYPE_T10</td>\n",
       "      <td>0.044840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASK_AMT</td>\n",
       "      <td>0.044696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>APPLICATION_TYPE_T19</td>\n",
       "      <td>0.040266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CLASSIFICATION_Other</td>\n",
       "      <td>0.038596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>APPLICATION_TYPE_T4</td>\n",
       "      <td>0.032880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APPLICATION_TYPE_T3</td>\n",
       "      <td>0.023084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>APPLICATION_TYPE_T6</td>\n",
       "      <td>0.020044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CLASSIFICATION_C2000</td>\n",
       "      <td>0.018481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>USE_CASE_ProductDev</td>\n",
       "      <td>0.015156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CLASSIFICATION_C3000</td>\n",
       "      <td>0.014581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>USE_CASE_Preservation</td>\n",
       "      <td>0.010716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ORGANIZATION_Co-operative</td>\n",
       "      <td>0.009458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CLASSIFICATION_C1200</td>\n",
       "      <td>0.009407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>INCOME_AMT_1M-5M</td>\n",
       "      <td>0.008356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>INCOME_AMT_1-9999</td>\n",
       "      <td>0.007742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>APPLICATION_TYPE_T8</td>\n",
       "      <td>0.004625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>INCOME_AMT_25000-99999</td>\n",
       "      <td>0.003786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>INCOME_AMT_10M-50M</td>\n",
       "      <td>0.003278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>INCOME_AMT_100000-499999</td>\n",
       "      <td>0.003009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>APPLICATION_TYPE_T7</td>\n",
       "      <td>0.002802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>INCOME_AMT_50M+</td>\n",
       "      <td>0.002018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>INCOME_AMT_5M-10M</td>\n",
       "      <td>0.001757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>INCOME_AMT_10000-24999</td>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AFFILIATION_Family/Parent</td>\n",
       "      <td>0.001005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>USE_CASE_Heathcare</td>\n",
       "      <td>0.000609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ORGANIZATION_Corporation</td>\n",
       "      <td>0.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AFFILIATION_National</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SPECIAL_CONSIDERATIONS_Y</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AFFILIATION_Regional</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AFFILIATION_Other</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>USE_CASE_Other</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STATUS</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Feature  Importance\n",
       "11    AFFILIATION_Independent    0.450664\n",
       "26         ORGANIZATION_Trust    0.083658\n",
       "17       CLASSIFICATION_C2100    0.055752\n",
       "6         APPLICATION_TYPE_T5    0.046338\n",
       "2        APPLICATION_TYPE_T10    0.044840\n",
       "1                     ASK_AMT    0.044696\n",
       "3        APPLICATION_TYPE_T19    0.040266\n",
       "19       CLASSIFICATION_Other    0.038596\n",
       "5         APPLICATION_TYPE_T4    0.032880\n",
       "4         APPLICATION_TYPE_T3    0.023084\n",
       "7         APPLICATION_TYPE_T6    0.020044\n",
       "16       CLASSIFICATION_C2000    0.018481\n",
       "23        USE_CASE_ProductDev    0.015156\n",
       "18       CLASSIFICATION_C3000    0.014581\n",
       "22      USE_CASE_Preservation    0.010716\n",
       "24  ORGANIZATION_Co-operative    0.009458\n",
       "15       CLASSIFICATION_C1200    0.009407\n",
       "31           INCOME_AMT_1M-5M    0.008356\n",
       "27          INCOME_AMT_1-9999    0.007742\n",
       "9         APPLICATION_TYPE_T8    0.004625\n",
       "32     INCOME_AMT_25000-99999    0.003786\n",
       "30         INCOME_AMT_10M-50M    0.003278\n",
       "29   INCOME_AMT_100000-499999    0.003009\n",
       "8         APPLICATION_TYPE_T7    0.002802\n",
       "33            INCOME_AMT_50M+    0.002018\n",
       "34          INCOME_AMT_5M-10M    0.001757\n",
       "28     INCOME_AMT_10000-24999    0.001567\n",
       "10  AFFILIATION_Family/Parent    0.001005\n",
       "20         USE_CASE_Heathcare    0.000609\n",
       "25   ORGANIZATION_Corporation    0.000520\n",
       "12       AFFILIATION_National    0.000193\n",
       "35   SPECIAL_CONSIDERATIONS_Y    0.000087\n",
       "14       AFFILIATION_Regional    0.000024\n",
       "13          AFFILIATION_Other    0.000005\n",
       "21             USE_CASE_Other    0.000000\n",
       "0                      STATUS    0.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features and target\n",
    "X = important_df.drop(columns='IS_SUCCESSFUL')\n",
    "y = important_df['IS_SUCCESSFUL']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300, 400],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Define an instance of GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Fit the gridsearch to the data\n",
    "best_rf = grid_search.best_estimator_\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict outcomes\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the random forest\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Additional classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Further evaluate feature importances\n",
    "feature_importances = best_rf.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "# Create a DataFrame for better readability\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After seeing which columns are most important, I think that it is safe to drop the following columns with less than 0.000500. This is because they offer either no value or little to no value to training the model. Making them excessive noise that should be cut out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "Accuracy: 0.7265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.69      3196\n",
      "           1       0.73      0.78      0.75      3664\n",
      "\n",
      "    accuracy                           0.73      6860\n",
      "   macro avg       0.73      0.72      0.72      6860\n",
      "weighted avg       0.73      0.73      0.73      6860\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AFFILIATION_Independent</td>\n",
       "      <td>0.433845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ORGANIZATION_Trust</td>\n",
       "      <td>0.085329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CLASSIFICATION_C2100</td>\n",
       "      <td>0.060145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>APPLICATION_TYPE_T5</td>\n",
       "      <td>0.047692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASK_AMT</td>\n",
       "      <td>0.045990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APPLICATION_TYPE_T10</td>\n",
       "      <td>0.043435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APPLICATION_TYPE_T19</td>\n",
       "      <td>0.043271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CLASSIFICATION_Other</td>\n",
       "      <td>0.041304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APPLICATION_TYPE_T4</td>\n",
       "      <td>0.036481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>APPLICATION_TYPE_T3</td>\n",
       "      <td>0.021566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>APPLICATION_TYPE_T6</td>\n",
       "      <td>0.020547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CLASSIFICATION_C2000</td>\n",
       "      <td>0.019948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>USE_CASE_ProductDev</td>\n",
       "      <td>0.014337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CLASSIFICATION_C3000</td>\n",
       "      <td>0.014110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>USE_CASE_Preservation</td>\n",
       "      <td>0.012048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CLASSIFICATION_C1200</td>\n",
       "      <td>0.010016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>INCOME_AMT_1M-5M</td>\n",
       "      <td>0.008887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ORGANIZATION_Co-operative</td>\n",
       "      <td>0.008552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>INCOME_AMT_1-9999</td>\n",
       "      <td>0.007891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>APPLICATION_TYPE_T8</td>\n",
       "      <td>0.004578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>INCOME_AMT_25000-99999</td>\n",
       "      <td>0.003743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>INCOME_AMT_100000-499999</td>\n",
       "      <td>0.003288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>APPLICATION_TYPE_T7</td>\n",
       "      <td>0.003154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>INCOME_AMT_10M-50M</td>\n",
       "      <td>0.002915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>INCOME_AMT_50M+</td>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>INCOME_AMT_10000-24999</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>INCOME_AMT_5M-10M</td>\n",
       "      <td>0.001431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AFFILIATION_Family/Parent</td>\n",
       "      <td>0.000971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>USE_CASE_Heathcare</td>\n",
       "      <td>0.000711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ORGANIZATION_Corporation</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Feature  Importance\n",
       "10    AFFILIATION_Independent    0.433845\n",
       "21         ORGANIZATION_Trust    0.085329\n",
       "13       CLASSIFICATION_C2100    0.060145\n",
       "5         APPLICATION_TYPE_T5    0.047692\n",
       "0                     ASK_AMT    0.045990\n",
       "1        APPLICATION_TYPE_T10    0.043435\n",
       "2        APPLICATION_TYPE_T19    0.043271\n",
       "15       CLASSIFICATION_Other    0.041304\n",
       "4         APPLICATION_TYPE_T4    0.036481\n",
       "3         APPLICATION_TYPE_T3    0.021566\n",
       "6         APPLICATION_TYPE_T6    0.020547\n",
       "12       CLASSIFICATION_C2000    0.019948\n",
       "18        USE_CASE_ProductDev    0.014337\n",
       "14       CLASSIFICATION_C3000    0.014110\n",
       "17      USE_CASE_Preservation    0.012048\n",
       "11       CLASSIFICATION_C1200    0.010016\n",
       "26           INCOME_AMT_1M-5M    0.008887\n",
       "19  ORGANIZATION_Co-operative    0.008552\n",
       "22          INCOME_AMT_1-9999    0.007891\n",
       "8         APPLICATION_TYPE_T8    0.004578\n",
       "27     INCOME_AMT_25000-99999    0.003743\n",
       "24   INCOME_AMT_100000-499999    0.003288\n",
       "7         APPLICATION_TYPE_T7    0.003154\n",
       "25         INCOME_AMT_10M-50M    0.002915\n",
       "28            INCOME_AMT_50M+    0.002009\n",
       "23     INCOME_AMT_10000-24999    0.001438\n",
       "29          INCOME_AMT_5M-10M    0.001431\n",
       "9   AFFILIATION_Family/Parent    0.000971\n",
       "16         USE_CASE_Heathcare    0.000711\n",
       "20   ORGANIZATION_Corporation    0.000369"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_df_2 = important_df.copy()\n",
    "\n",
    "# Identify features with zero importance\n",
    "low_importance_features = feature_importance_df[feature_importance_df['Importance'] <= 0.000500]['Feature'].tolist()\n",
    "\n",
    "# Remove the useless columns\n",
    "important_df_2 = important_df_2.drop(columns=low_importance_features)\n",
    "\n",
    "# run importance model again to make sure things didn't drastically change\n",
    "# Define features and target\n",
    "X = important_df.drop(columns='IS_SUCCESSFUL')\n",
    "y = important_df['IS_SUCCESSFUL']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300, 400],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Define an instance of GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Fit the gridsearch to the data\n",
    "best_rf = grid_search.best_estimator_\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict outcomes\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the random forest\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Additional classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Further evaluate feature importances\n",
    "feature_importances = best_rf.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "# Create a DataFrame for better readability\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Counts for the column named: ASK_AMT\n",
      "ASK_AMT\n",
      "5000        25398\n",
      "10478           3\n",
      "15583           3\n",
      "63981           3\n",
      "6725            3\n",
      "            ...  \n",
      "5371754         1\n",
      "30060           1\n",
      "43091152        1\n",
      "18683           1\n",
      "36500179        1\n",
      "Name: count, Length: 8747, dtype: int64\n",
      "Value Counts for the column named: IS_SUCCESSFUL\n",
      "IS_SUCCESSFUL\n",
      "1    18261\n",
      "0    16038\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: APPLICATION_TYPE_T10\n",
      "APPLICATION_TYPE_T10\n",
      "False    33771\n",
      "True       528\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: APPLICATION_TYPE_T19\n",
      "APPLICATION_TYPE_T19\n",
      "False    33234\n",
      "True      1065\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: APPLICATION_TYPE_T3\n",
      "APPLICATION_TYPE_T3\n",
      "True     27037\n",
      "False     7262\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: APPLICATION_TYPE_T4\n",
      "APPLICATION_TYPE_T4\n",
      "False    32757\n",
      "True      1542\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: APPLICATION_TYPE_T5\n",
      "APPLICATION_TYPE_T5\n",
      "False    33126\n",
      "True      1173\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: APPLICATION_TYPE_T6\n",
      "APPLICATION_TYPE_T6\n",
      "False    33083\n",
      "True      1216\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: APPLICATION_TYPE_T7\n",
      "APPLICATION_TYPE_T7\n",
      "False    33574\n",
      "True       725\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: APPLICATION_TYPE_T8\n",
      "APPLICATION_TYPE_T8\n",
      "False    33562\n",
      "True       737\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: AFFILIATION_Family/Parent\n",
      "AFFILIATION_Family/Parent\n",
      "False    34235\n",
      "True        64\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: AFFILIATION_Independent\n",
      "AFFILIATION_Independent\n",
      "True     18480\n",
      "False    15819\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: CLASSIFICATION_C1200\n",
      "CLASSIFICATION_C1200\n",
      "False    29462\n",
      "True      4837\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: CLASSIFICATION_C2000\n",
      "CLASSIFICATION_C2000\n",
      "False    28225\n",
      "True      6074\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: CLASSIFICATION_C2100\n",
      "CLASSIFICATION_C2100\n",
      "False    32416\n",
      "True      1883\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: CLASSIFICATION_C3000\n",
      "CLASSIFICATION_C3000\n",
      "False    32381\n",
      "True      1918\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: CLASSIFICATION_Other\n",
      "CLASSIFICATION_Other\n",
      "False    32038\n",
      "True      2261\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: USE_CASE_Heathcare\n",
      "USE_CASE_Heathcare\n",
      "False    34153\n",
      "True       146\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: USE_CASE_Preservation\n",
      "USE_CASE_Preservation\n",
      "True     28095\n",
      "False     6204\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: USE_CASE_ProductDev\n",
      "USE_CASE_ProductDev\n",
      "False    28628\n",
      "True      5671\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: ORGANIZATION_Co-operative\n",
      "ORGANIZATION_Co-operative\n",
      "False    33813\n",
      "True       486\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: ORGANIZATION_Corporation\n",
      "ORGANIZATION_Corporation\n",
      "False    34256\n",
      "True        43\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: ORGANIZATION_Trust\n",
      "ORGANIZATION_Trust\n",
      "True     23515\n",
      "False    10784\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: INCOME_AMT_1-9999\n",
      "INCOME_AMT_1-9999\n",
      "False    33571\n",
      "True       728\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: INCOME_AMT_10000-24999\n",
      "INCOME_AMT_10000-24999\n",
      "False    33756\n",
      "True       543\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: INCOME_AMT_100000-499999\n",
      "INCOME_AMT_100000-499999\n",
      "False    30925\n",
      "True      3374\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: INCOME_AMT_10M-50M\n",
      "INCOME_AMT_10M-50M\n",
      "False    34059\n",
      "True       240\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: INCOME_AMT_1M-5M\n",
      "INCOME_AMT_1M-5M\n",
      "False    33344\n",
      "True       955\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: INCOME_AMT_25000-99999\n",
      "INCOME_AMT_25000-99999\n",
      "False    30552\n",
      "True      3747\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: INCOME_AMT_50M+\n",
      "INCOME_AMT_50M+\n",
      "False    34160\n",
      "True       139\n",
      "Name: count, dtype: int64\n",
      "Value Counts for the column named: INCOME_AMT_5M-10M\n",
      "INCOME_AMT_5M-10M\n",
      "False    34114\n",
      "True       185\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check value counts\n",
    "# Define columns\n",
    "all_columns = important_df_2.columns.tolist()\n",
    "\n",
    "for i in all_columns:\n",
    "    print(f'Value Counts for the column named: {i}')\n",
    "    print(important_df_2[i].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (27439, 30)\n",
      "Test Data Shape: (6860, 30)\n"
     ]
    }
   ],
   "source": [
    "# Copy the important_df\n",
    "optimization_df_1 = important_df_2.copy()\n",
    "\n",
    "# Build the model optimization attempt one.\n",
    "# Define features and target\n",
    "X = optimization_df_1.drop(columns='IS_SUCCESSFUL')\n",
    "y = optimization_df_1['IS_SUCCESSFUL']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Check dimensions\n",
    "print(f\"Training Data Shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test Data Shape: {X_test_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 25)                775       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 110)               2860      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 285)               31635     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 135)               38610     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 210)               28560     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 211       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102651 (400.98 KB)\n",
      "Trainable params: 102651 (400.98 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First units layer\n",
    "nn.add(tf.keras.layers.Dense(units=25, activation=\"relu\", input_dim=30))\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=110, activation=\"relu\"))  # units_0\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=285, activation=\"relu\"))  # units_1\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=135, activation=\"relu\"))  # units_2\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=210, activation=\"relu\"))  # units_3\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "858/858 [==============================] - 6s 4ms/step - loss: 0.5712 - accuracy: 0.7195\n",
      "Epoch 2/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5563 - accuracy: 0.7290\n",
      "Epoch 3/100\n",
      "858/858 [==============================] - 4s 4ms/step - loss: 0.5536 - accuracy: 0.7293\n",
      "Epoch 4/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5515 - accuracy: 0.7315\n",
      "Epoch 5/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5504 - accuracy: 0.7314\n",
      "Epoch 6/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5486 - accuracy: 0.7326\n",
      "Epoch 7/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5480 - accuracy: 0.7334\n",
      "Epoch 8/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5466 - accuracy: 0.7344\n",
      "Epoch 9/100\n",
      "858/858 [==============================] - 5s 6ms/step - loss: 0.5467 - accuracy: 0.7340\n",
      "Epoch 10/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5464 - accuracy: 0.7343\n",
      "Epoch 11/100\n",
      "858/858 [==============================] - 4s 5ms/step - loss: 0.5454 - accuracy: 0.7348\n",
      "Epoch 12/100\n",
      "858/858 [==============================] - 4s 5ms/step - loss: 0.5445 - accuracy: 0.7354\n",
      "Epoch 13/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5444 - accuracy: 0.7349\n",
      "Epoch 14/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5439 - accuracy: 0.7354\n",
      "Epoch 15/100\n",
      "858/858 [==============================] - 5s 5ms/step - loss: 0.5432 - accuracy: 0.7354\n",
      "Epoch 16/100\n",
      "858/858 [==============================] - 4s 4ms/step - loss: 0.5430 - accuracy: 0.7362\n",
      "Epoch 17/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5423 - accuracy: 0.7365\n",
      "Epoch 18/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5423 - accuracy: 0.7358\n",
      "Epoch 19/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5416 - accuracy: 0.7373\n",
      "Epoch 20/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5413 - accuracy: 0.7358\n",
      "Epoch 21/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5411 - accuracy: 0.7377\n",
      "Epoch 22/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5410 - accuracy: 0.7373\n",
      "Epoch 23/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5412 - accuracy: 0.7376\n",
      "Epoch 24/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5397 - accuracy: 0.7376\n",
      "Epoch 25/100\n",
      "858/858 [==============================] - 4s 5ms/step - loss: 0.5398 - accuracy: 0.7373\n",
      "Epoch 26/100\n",
      "858/858 [==============================] - 4s 4ms/step - loss: 0.5397 - accuracy: 0.7372\n",
      "Epoch 27/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5390 - accuracy: 0.7386\n",
      "Epoch 28/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5395 - accuracy: 0.7375\n",
      "Epoch 29/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5388 - accuracy: 0.7379\n",
      "Epoch 30/100\n",
      "858/858 [==============================] - 4s 5ms/step - loss: 0.5387 - accuracy: 0.7385\n",
      "Epoch 31/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5388 - accuracy: 0.7382\n",
      "Epoch 32/100\n",
      "858/858 [==============================] - 4s 5ms/step - loss: 0.5380 - accuracy: 0.7383\n",
      "Epoch 33/100\n",
      "858/858 [==============================] - 4s 4ms/step - loss: 0.5386 - accuracy: 0.7377\n",
      "Epoch 34/100\n",
      "858/858 [==============================] - 4s 4ms/step - loss: 0.5380 - accuracy: 0.7393\n",
      "Epoch 35/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5372 - accuracy: 0.7386\n",
      "Epoch 36/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5385 - accuracy: 0.7380\n",
      "Epoch 37/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5374 - accuracy: 0.7386\n",
      "Epoch 38/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5375 - accuracy: 0.7380\n",
      "Epoch 39/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5370 - accuracy: 0.7389\n",
      "Epoch 40/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5376 - accuracy: 0.7383\n",
      "Epoch 41/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5373 - accuracy: 0.7384\n",
      "Epoch 42/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5371 - accuracy: 0.7387\n",
      "Epoch 43/100\n",
      "858/858 [==============================] - 4s 5ms/step - loss: 0.5358 - accuracy: 0.7390\n",
      "Epoch 44/100\n",
      "858/858 [==============================] - 4s 5ms/step - loss: 0.5364 - accuracy: 0.7385\n",
      "Epoch 45/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5371 - accuracy: 0.7387\n",
      "Epoch 46/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5368 - accuracy: 0.7399\n",
      "Epoch 47/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5362 - accuracy: 0.7389\n",
      "Epoch 48/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5360 - accuracy: 0.7391\n",
      "Epoch 49/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5366 - accuracy: 0.7385\n",
      "Epoch 50/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5361 - accuracy: 0.7390\n",
      "Epoch 51/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5362 - accuracy: 0.7392\n",
      "Epoch 52/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5353 - accuracy: 0.7395\n",
      "Epoch 53/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5357 - accuracy: 0.7399\n",
      "Epoch 54/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5357 - accuracy: 0.7392\n",
      "Epoch 55/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5351 - accuracy: 0.7389\n",
      "Epoch 56/100\n",
      "858/858 [==============================] - 4s 5ms/step - loss: 0.5362 - accuracy: 0.7394\n",
      "Epoch 57/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5350 - accuracy: 0.7401\n",
      "Epoch 58/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5364 - accuracy: 0.7385\n",
      "Epoch 59/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5353 - accuracy: 0.7392\n",
      "Epoch 60/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5350 - accuracy: 0.7384\n",
      "Epoch 61/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5347 - accuracy: 0.7395\n",
      "Epoch 62/100\n",
      "858/858 [==============================] - 4s 4ms/step - loss: 0.5355 - accuracy: 0.7394\n",
      "Epoch 63/100\n",
      "858/858 [==============================] - 5s 6ms/step - loss: 0.5349 - accuracy: 0.7393\n",
      "Epoch 64/100\n",
      "858/858 [==============================] - 4s 5ms/step - loss: 0.5361 - accuracy: 0.7400\n",
      "Epoch 65/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5347 - accuracy: 0.7392\n",
      "Epoch 66/100\n",
      "858/858 [==============================] - 5s 5ms/step - loss: 0.5344 - accuracy: 0.7397\n",
      "Epoch 67/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5339 - accuracy: 0.7397\n",
      "Epoch 68/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5346 - accuracy: 0.7403\n",
      "Epoch 69/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5360 - accuracy: 0.7399\n",
      "Epoch 70/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5345 - accuracy: 0.7391\n",
      "Epoch 71/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5338 - accuracy: 0.7396\n",
      "Epoch 72/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5353 - accuracy: 0.7393\n",
      "Epoch 73/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5368 - accuracy: 0.7393\n",
      "Epoch 74/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5350 - accuracy: 0.7395\n",
      "Epoch 75/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5337 - accuracy: 0.7407\n",
      "Epoch 76/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5341 - accuracy: 0.7389\n",
      "Epoch 77/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5347 - accuracy: 0.7392\n",
      "Epoch 78/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5349 - accuracy: 0.7396\n",
      "Epoch 79/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5336 - accuracy: 0.7396\n",
      "Epoch 80/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5337 - accuracy: 0.7400\n",
      "Epoch 81/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5338 - accuracy: 0.7400\n",
      "Epoch 82/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5335 - accuracy: 0.7399\n",
      "Epoch 83/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5337 - accuracy: 0.7392\n",
      "Epoch 84/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5356 - accuracy: 0.7396\n",
      "Epoch 85/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5338 - accuracy: 0.7406\n",
      "Epoch 86/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5340 - accuracy: 0.7399\n",
      "Epoch 87/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5348 - accuracy: 0.7401\n",
      "Epoch 88/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5341 - accuracy: 0.7398\n",
      "Epoch 89/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5330 - accuracy: 0.7401\n",
      "Epoch 90/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5333 - accuracy: 0.7402\n",
      "Epoch 91/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5341 - accuracy: 0.7400\n",
      "Epoch 92/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5335 - accuracy: 0.7406\n",
      "Epoch 93/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5339 - accuracy: 0.7397\n",
      "Epoch 94/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5375 - accuracy: 0.7396\n",
      "Epoch 95/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5339 - accuracy: 0.7395\n",
      "Epoch 96/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5330 - accuracy: 0.7403\n",
      "Epoch 97/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5333 - accuracy: 0.7400\n",
      "Epoch 98/100\n",
      "858/858 [==============================] - 4s 5ms/step - loss: 0.5336 - accuracy: 0.7397\n",
      "Epoch 99/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5339 - accuracy: 0.7400\n",
      "Epoch 100/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5339 - accuracy: 0.7401\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model = nn.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 1s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.65      0.69      3196\n",
      "           1       0.72      0.79      0.76      3664\n",
      "\n",
      "    accuracy                           0.73      6860\n",
      "   macro avg       0.73      0.72      0.72      6860\n",
      "weighted avg       0.73      0.73      0.73      6860\n",
      "\n",
      "215/215 - 1s - loss: 0.5911 - accuracy: 0.7277 - 558ms/epoch - 3ms/step\n",
      "Loss: 0.5910669565200806, Accuracy: 0.7276967763900757\n"
     ]
    }
   ],
   "source": [
    "# Get classification_report\n",
    "y_pred_prob = nn.predict(X_test_scaled)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)  \n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"AlphabetSoupCharity_OptimizationAttempt1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization attempt 2:\n",
    "Because the target variable is slightly imbalanced, I want to see if there is a way to oversample the data to help the model get more even distribution in target values. Implementing SMOTE to balance the target variables in the trianing set to see if performance increases or decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (29194, 29)\n",
      "Test Data Shape: (6860, 29)\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of application df\n",
    "optimization_df_2 = important_df_2.copy()\n",
    "\n",
    "# Build the model attempt two\n",
    "# Define features and target\n",
    "X = optimization_df_2.drop(columns='IS_SUCCESSFUL')\n",
    "y = optimization_df_2['IS_SUCCESSFUL']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to balance the target variable in the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Check dimensions\n",
    "print(f\"Training Data Shape: {X_train_resampled.shape}\")\n",
    "print(f\"Test Data Shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 25)                750       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 110)               2860      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 285)               31635     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 135)               38610     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 210)               28560     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 211       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102626 (400.88 KB)\n",
      "Trainable params: 102626 (400.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "nn_2 = tf.keras.models.Sequential()\n",
    "\n",
    "# First units layer\n",
    "nn_2.add(tf.keras.layers.Dense(units=25, activation=\"relu\", input_dim=29))\n",
    "\n",
    "# First hidden layer\n",
    "nn_2.add(tf.keras.layers.Dense(units=110, activation=\"relu\"))  # units_0\n",
    "\n",
    "# Second hidden layer\n",
    "nn_2.add(tf.keras.layers.Dense(units=285, activation=\"relu\"))  # units_1\n",
    "\n",
    "# Third hidden layer\n",
    "nn_2.add(tf.keras.layers.Dense(units=135, activation=\"relu\"))  # units_2\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn_2.add(tf.keras.layers.Dense(units=210, activation=\"relu\"))  # units_3\n",
    "\n",
    "# Output layer\n",
    "nn_2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "913/913 [==============================] - 4s 3ms/step - loss: 0.5698 - accuracy: 0.7183\n",
      "Epoch 2/100\n",
      "913/913 [==============================] - 2s 3ms/step - loss: 0.5572 - accuracy: 0.7259\n",
      "Epoch 3/100\n",
      "913/913 [==============================] - 2s 2ms/step - loss: 0.5546 - accuracy: 0.7265\n",
      "Epoch 4/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5526 - accuracy: 0.7286\n",
      "Epoch 5/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5506 - accuracy: 0.7300\n",
      "Epoch 6/100\n",
      "913/913 [==============================] - 2s 3ms/step - loss: 0.5504 - accuracy: 0.7292\n",
      "Epoch 7/100\n",
      "913/913 [==============================] - 2s 3ms/step - loss: 0.5497 - accuracy: 0.7300\n",
      "Epoch 8/100\n",
      "913/913 [==============================] - 2s 2ms/step - loss: 0.5496 - accuracy: 0.7308\n",
      "Epoch 9/100\n",
      "913/913 [==============================] - 2s 3ms/step - loss: 0.5482 - accuracy: 0.7306\n",
      "Epoch 10/100\n",
      "913/913 [==============================] - 2s 3ms/step - loss: 0.5478 - accuracy: 0.7308\n",
      "Epoch 11/100\n",
      "913/913 [==============================] - 2s 3ms/step - loss: 0.5468 - accuracy: 0.7313\n",
      "Epoch 12/100\n",
      "913/913 [==============================] - 2s 3ms/step - loss: 0.5460 - accuracy: 0.7311\n",
      "Epoch 13/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5459 - accuracy: 0.7326\n",
      "Epoch 14/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5453 - accuracy: 0.7327\n",
      "Epoch 15/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5446 - accuracy: 0.7327\n",
      "Epoch 16/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5449 - accuracy: 0.7315\n",
      "Epoch 17/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5443 - accuracy: 0.7323\n",
      "Epoch 18/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5439 - accuracy: 0.7323\n",
      "Epoch 19/100\n",
      "913/913 [==============================] - 2s 3ms/step - loss: 0.5438 - accuracy: 0.7336\n",
      "Epoch 20/100\n",
      "913/913 [==============================] - 2s 3ms/step - loss: 0.5434 - accuracy: 0.7332\n",
      "Epoch 21/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5432 - accuracy: 0.7328\n",
      "Epoch 22/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5421 - accuracy: 0.7343\n",
      "Epoch 23/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5424 - accuracy: 0.7333\n",
      "Epoch 24/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5418 - accuracy: 0.7336\n",
      "Epoch 25/100\n",
      "913/913 [==============================] - 7s 8ms/step - loss: 0.5419 - accuracy: 0.7335\n",
      "Epoch 26/100\n",
      "913/913 [==============================] - 4s 4ms/step - loss: 0.5425 - accuracy: 0.7345\n",
      "Epoch 27/100\n",
      "913/913 [==============================] - 4s 4ms/step - loss: 0.5412 - accuracy: 0.7346\n",
      "Epoch 28/100\n",
      "913/913 [==============================] - 5s 5ms/step - loss: 0.5409 - accuracy: 0.7338\n",
      "Epoch 29/100\n",
      "913/913 [==============================] - 5s 5ms/step - loss: 0.5407 - accuracy: 0.7346\n",
      "Epoch 30/100\n",
      "913/913 [==============================] - 10s 11ms/step - loss: 0.5408 - accuracy: 0.7351\n",
      "Epoch 31/100\n",
      "913/913 [==============================] - 10s 11ms/step - loss: 0.5409 - accuracy: 0.7346\n",
      "Epoch 32/100\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.5399 - accuracy: 0.7350\n",
      "Epoch 33/100\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.5398 - accuracy: 0.7358\n",
      "Epoch 34/100\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.5408 - accuracy: 0.7345\n",
      "Epoch 35/100\n",
      "913/913 [==============================] - 5s 5ms/step - loss: 0.5394 - accuracy: 0.7353\n",
      "Epoch 36/100\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.5401 - accuracy: 0.7345\n",
      "Epoch 37/100\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.5394 - accuracy: 0.7353\n",
      "Epoch 38/100\n",
      "913/913 [==============================] - 4s 4ms/step - loss: 0.5391 - accuracy: 0.7354\n",
      "Epoch 39/100\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.5397 - accuracy: 0.7350\n",
      "Epoch 40/100\n",
      "913/913 [==============================] - 5s 5ms/step - loss: 0.5390 - accuracy: 0.7355\n",
      "Epoch 41/100\n",
      "913/913 [==============================] - 5s 6ms/step - loss: 0.5397 - accuracy: 0.7354\n",
      "Epoch 42/100\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.5387 - accuracy: 0.7363\n",
      "Epoch 43/100\n",
      "913/913 [==============================] - 4s 4ms/step - loss: 0.5387 - accuracy: 0.7358\n",
      "Epoch 44/100\n",
      "913/913 [==============================] - 3s 4ms/step - loss: 0.5383 - accuracy: 0.7358\n",
      "Epoch 45/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5381 - accuracy: 0.7363\n",
      "Epoch 46/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5382 - accuracy: 0.7360\n",
      "Epoch 47/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5387 - accuracy: 0.7356\n",
      "Epoch 48/100\n",
      "913/913 [==============================] - 3s 4ms/step - loss: 0.5378 - accuracy: 0.7354\n",
      "Epoch 49/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5379 - accuracy: 0.7365\n",
      "Epoch 50/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5375 - accuracy: 0.7360\n",
      "Epoch 51/100\n",
      "913/913 [==============================] - 4s 4ms/step - loss: 0.5388 - accuracy: 0.7355\n",
      "Epoch 52/100\n",
      "913/913 [==============================] - 3s 4ms/step - loss: 0.5381 - accuracy: 0.7363\n",
      "Epoch 53/100\n",
      "913/913 [==============================] - 2s 3ms/step - loss: 0.5371 - accuracy: 0.7360\n",
      "Epoch 54/100\n",
      "913/913 [==============================] - 4s 4ms/step - loss: 0.5366 - accuracy: 0.7366\n",
      "Epoch 55/100\n",
      "913/913 [==============================] - 4s 4ms/step - loss: 0.5369 - accuracy: 0.7367\n",
      "Epoch 56/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5382 - accuracy: 0.7367\n",
      "Epoch 57/100\n",
      "913/913 [==============================] - 2s 3ms/step - loss: 0.5368 - accuracy: 0.7368\n",
      "Epoch 58/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5369 - accuracy: 0.7361\n",
      "Epoch 59/100\n",
      "913/913 [==============================] - 2s 3ms/step - loss: 0.5385 - accuracy: 0.7355\n",
      "Epoch 60/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5370 - accuracy: 0.7357\n",
      "Epoch 61/100\n",
      "913/913 [==============================] - 3s 4ms/step - loss: 0.5374 - accuracy: 0.7367\n",
      "Epoch 62/100\n",
      "913/913 [==============================] - 3s 4ms/step - loss: 0.5361 - accuracy: 0.7368\n",
      "Epoch 63/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5362 - accuracy: 0.7363\n",
      "Epoch 64/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5365 - accuracy: 0.7365\n",
      "Epoch 65/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5368 - accuracy: 0.7365\n",
      "Epoch 66/100\n",
      "913/913 [==============================] - 3s 4ms/step - loss: 0.5373 - accuracy: 0.7363\n",
      "Epoch 67/100\n",
      "913/913 [==============================] - 3s 4ms/step - loss: 0.5371 - accuracy: 0.7343\n",
      "Epoch 68/100\n",
      "913/913 [==============================] - 2s 3ms/step - loss: 0.5364 - accuracy: 0.7363\n",
      "Epoch 69/100\n",
      "913/913 [==============================] - 5s 5ms/step - loss: 0.5374 - accuracy: 0.7359\n",
      "Epoch 70/100\n",
      "913/913 [==============================] - 4s 4ms/step - loss: 0.5361 - accuracy: 0.7365\n",
      "Epoch 71/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5364 - accuracy: 0.7364\n",
      "Epoch 72/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5364 - accuracy: 0.7369\n",
      "Epoch 73/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5373 - accuracy: 0.7369\n",
      "Epoch 74/100\n",
      "913/913 [==============================] - 6s 7ms/step - loss: 0.5363 - accuracy: 0.7371\n",
      "Epoch 75/100\n",
      "913/913 [==============================] - 8s 9ms/step - loss: 0.5357 - accuracy: 0.7379\n",
      "Epoch 76/100\n",
      "913/913 [==============================] - 8s 9ms/step - loss: 0.5363 - accuracy: 0.7367\n",
      "Epoch 77/100\n",
      "913/913 [==============================] - 8s 9ms/step - loss: 0.5370 - accuracy: 0.7370\n",
      "Epoch 78/100\n",
      "913/913 [==============================] - 7s 8ms/step - loss: 0.5367 - accuracy: 0.7365\n",
      "Epoch 79/100\n",
      "913/913 [==============================] - 5s 6ms/step - loss: 0.5364 - accuracy: 0.7365\n",
      "Epoch 80/100\n",
      "913/913 [==============================] - 5s 5ms/step - loss: 0.5358 - accuracy: 0.7370\n",
      "Epoch 81/100\n",
      "913/913 [==============================] - 6s 7ms/step - loss: 0.5354 - accuracy: 0.7366\n",
      "Epoch 82/100\n",
      "913/913 [==============================] - 5s 6ms/step - loss: 0.5357 - accuracy: 0.7372\n",
      "Epoch 83/100\n",
      "913/913 [==============================] - 4s 4ms/step - loss: 0.5372 - accuracy: 0.7373\n",
      "Epoch 84/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5371 - accuracy: 0.7365\n",
      "Epoch 85/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5357 - accuracy: 0.7370\n",
      "Epoch 86/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5359 - accuracy: 0.7367\n",
      "Epoch 87/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5359 - accuracy: 0.7370\n",
      "Epoch 88/100\n",
      "913/913 [==============================] - 4s 4ms/step - loss: 0.5358 - accuracy: 0.7372\n",
      "Epoch 89/100\n",
      "913/913 [==============================] - 6s 6ms/step - loss: 0.5360 - accuracy: 0.7375\n",
      "Epoch 90/100\n",
      "913/913 [==============================] - 4s 4ms/step - loss: 0.5362 - accuracy: 0.7359\n",
      "Epoch 91/100\n",
      "913/913 [==============================] - 3s 4ms/step - loss: 0.5353 - accuracy: 0.7374\n",
      "Epoch 92/100\n",
      "913/913 [==============================] - 3s 4ms/step - loss: 0.5369 - accuracy: 0.7369\n",
      "Epoch 93/100\n",
      "913/913 [==============================] - 3s 4ms/step - loss: 0.5360 - accuracy: 0.7370\n",
      "Epoch 94/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5351 - accuracy: 0.7374\n",
      "Epoch 95/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5363 - accuracy: 0.7367\n",
      "Epoch 96/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5356 - accuracy: 0.7364\n",
      "Epoch 97/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5359 - accuracy: 0.7365\n",
      "Epoch 98/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5353 - accuracy: 0.7368\n",
      "Epoch 99/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5353 - accuracy: 0.7367\n",
      "Epoch 100/100\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.5393 - accuracy: 0.7366\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model_2 = nn_2.fit(X_train_resampled, y_train_resampled, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 1s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.70      3196\n",
      "           1       0.73      0.76      0.74      3664\n",
      "\n",
      "    accuracy                           0.72      6860\n",
      "   macro avg       0.72      0.72      0.72      6860\n",
      "weighted avg       0.72      0.72      0.72      6860\n",
      "\n",
      "215/215 - 0s - loss: 0.5741 - accuracy: 0.7224 - 460ms/epoch - 2ms/step\n",
      "Loss: 0.5740903615951538, Accuracy: 0.722449004650116\n"
     ]
    }
   ],
   "source": [
    "# Get classification_report\n",
    "y_pred_prob_2 = nn_2.predict(X_test_scaled)\n",
    "y_pred_2 = (y_pred_prob_2 > 0.5).astype(int)  \n",
    "print(classification_report(y_test, y_pred_2))\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_2.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn_2.save(\"AlphabetSoupCharity_OptimizationAttempt2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Attempt 3:\n",
    "Since smote didnt increase the accuracy and because there is such a large imbalance in the ASK_AMT value counts, I want to turn the entire column into a binary column where the values are either 0, values equal to 5000, or 1, every other value in the column. Then I want to run the model without smote to see if the accuracy increases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASK_AMT_Binary\n",
      "0    25398\n",
      "1     8901\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "optimization_df_3 = important_df_2.copy()\n",
    "\n",
    "# Create a binary column where 5000 is 0 and all other values are 1\n",
    "optimization_df_3[\"ASK_AMT_Binary\"] = (optimization_df_3[\"ASK_AMT\"] != 5000).astype(int)\n",
    "\n",
    "# Drop Original column\n",
    "optimization_df_3 = optimization_df_3.drop(columns=(['ASK_AMT']))\n",
    "\n",
    "# Display value counts for the binary column\n",
    "print(optimization_df_3[\"ASK_AMT_Binary\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (27439, 29)\n",
      "Test Data Shape: (6860, 29)\n"
     ]
    }
   ],
   "source": [
    "# Build the model optimization attempt three.\n",
    "# Define features and target\n",
    "X = optimization_df_3.drop(columns='IS_SUCCESSFUL')\n",
    "y = optimization_df_3['IS_SUCCESSFUL']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Check dimensions\n",
    "print(f\"Training Data Shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test Data Shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 25)                750       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 110)               2860      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 285)               31635     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 135)               38610     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 210)               28560     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 211       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102626 (400.88 KB)\n",
      "Trainable params: 102626 (400.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "nn_3 = tf.keras.models.Sequential()\n",
    "\n",
    "# First units layer\n",
    "nn_3.add(tf.keras.layers.Dense(units=25, activation=\"relu\", input_dim=29))\n",
    "\n",
    "# First hidden layer\n",
    "nn_3.add(tf.keras.layers.Dense(units=110, activation=\"relu\"))  # units_0\n",
    "\n",
    "# Second hidden layer\n",
    "nn_3.add(tf.keras.layers.Dense(units=285, activation=\"relu\"))  # units_1\n",
    "\n",
    "# Third hidden layer\n",
    "nn_3.add(tf.keras.layers.Dense(units=135, activation=\"relu\"))  # units_2\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn_3.add(tf.keras.layers.Dense(units=210, activation=\"relu\"))  # units_3\n",
    "\n",
    "# Output layer\n",
    "nn_3.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "858/858 [==============================] - 4s 3ms/step - loss: 0.5700 - accuracy: 0.7208\n",
      "Epoch 2/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5564 - accuracy: 0.7286\n",
      "Epoch 3/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5521 - accuracy: 0.7304\n",
      "Epoch 4/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5507 - accuracy: 0.7299\n",
      "Epoch 5/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5495 - accuracy: 0.7315\n",
      "Epoch 6/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5483 - accuracy: 0.7324\n",
      "Epoch 7/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5470 - accuracy: 0.7330\n",
      "Epoch 8/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5464 - accuracy: 0.7332\n",
      "Epoch 9/100\n",
      "858/858 [==============================] - 4s 4ms/step - loss: 0.5461 - accuracy: 0.7332\n",
      "Epoch 10/100\n",
      "858/858 [==============================] - 4s 4ms/step - loss: 0.5454 - accuracy: 0.7332\n",
      "Epoch 11/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5445 - accuracy: 0.7347\n",
      "Epoch 12/100\n",
      "858/858 [==============================] - 4s 5ms/step - loss: 0.5438 - accuracy: 0.7352\n",
      "Epoch 13/100\n",
      "858/858 [==============================] - 6s 8ms/step - loss: 0.5433 - accuracy: 0.7361\n",
      "Epoch 14/100\n",
      "858/858 [==============================] - 8s 10ms/step - loss: 0.5432 - accuracy: 0.7357\n",
      "Epoch 15/100\n",
      "858/858 [==============================] - 6s 7ms/step - loss: 0.5423 - accuracy: 0.7351\n",
      "Epoch 16/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5411 - accuracy: 0.7363\n",
      "Epoch 17/100\n",
      "858/858 [==============================] - 4s 4ms/step - loss: 0.5419 - accuracy: 0.7353\n",
      "Epoch 18/100\n",
      "858/858 [==============================] - 4s 4ms/step - loss: 0.5408 - accuracy: 0.7364\n",
      "Epoch 19/100\n",
      "858/858 [==============================] - 4s 4ms/step - loss: 0.5401 - accuracy: 0.7368\n",
      "Epoch 20/100\n",
      "858/858 [==============================] - 5s 6ms/step - loss: 0.5403 - accuracy: 0.7364\n",
      "Epoch 21/100\n",
      "858/858 [==============================] - 6s 7ms/step - loss: 0.5400 - accuracy: 0.7364\n",
      "Epoch 22/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5398 - accuracy: 0.7369\n",
      "Epoch 23/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5392 - accuracy: 0.7365\n",
      "Epoch 24/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5389 - accuracy: 0.7375\n",
      "Epoch 25/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5388 - accuracy: 0.7374\n",
      "Epoch 26/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5379 - accuracy: 0.7378\n",
      "Epoch 27/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5376 - accuracy: 0.7383\n",
      "Epoch 28/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5377 - accuracy: 0.7380\n",
      "Epoch 29/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5378 - accuracy: 0.7381\n",
      "Epoch 30/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5367 - accuracy: 0.7384\n",
      "Epoch 31/100\n",
      "858/858 [==============================] - 4s 4ms/step - loss: 0.5364 - accuracy: 0.7392\n",
      "Epoch 32/100\n",
      "858/858 [==============================] - 4s 5ms/step - loss: 0.5369 - accuracy: 0.7388\n",
      "Epoch 33/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5360 - accuracy: 0.7386\n",
      "Epoch 34/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5364 - accuracy: 0.7381\n",
      "Epoch 35/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5358 - accuracy: 0.7390\n",
      "Epoch 36/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5359 - accuracy: 0.7389\n",
      "Epoch 37/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5357 - accuracy: 0.7387\n",
      "Epoch 38/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5368 - accuracy: 0.7381\n",
      "Epoch 39/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5348 - accuracy: 0.7391\n",
      "Epoch 40/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5360 - accuracy: 0.7390\n",
      "Epoch 41/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5351 - accuracy: 0.7395\n",
      "Epoch 42/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5350 - accuracy: 0.7391\n",
      "Epoch 43/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5347 - accuracy: 0.7404\n",
      "Epoch 44/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5345 - accuracy: 0.7395\n",
      "Epoch 45/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5344 - accuracy: 0.7389\n",
      "Epoch 46/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5337 - accuracy: 0.7396\n",
      "Epoch 47/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5349 - accuracy: 0.7400\n",
      "Epoch 48/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5339 - accuracy: 0.7400\n",
      "Epoch 49/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5343 - accuracy: 0.7400\n",
      "Epoch 50/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5349 - accuracy: 0.7392\n",
      "Epoch 51/100\n",
      "858/858 [==============================] - 4s 5ms/step - loss: 0.5338 - accuracy: 0.7402\n",
      "Epoch 52/100\n",
      "858/858 [==============================] - 5s 6ms/step - loss: 0.5338 - accuracy: 0.7400\n",
      "Epoch 53/100\n",
      "858/858 [==============================] - 5s 6ms/step - loss: 0.5328 - accuracy: 0.7403\n",
      "Epoch 54/100\n",
      "858/858 [==============================] - 5s 5ms/step - loss: 0.5337 - accuracy: 0.7402\n",
      "Epoch 55/100\n",
      "858/858 [==============================] - 4s 5ms/step - loss: 0.5335 - accuracy: 0.7396\n",
      "Epoch 56/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5343 - accuracy: 0.7404\n",
      "Epoch 57/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5338 - accuracy: 0.7391\n",
      "Epoch 58/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5335 - accuracy: 0.7387\n",
      "Epoch 59/100\n",
      "858/858 [==============================] - 4s 5ms/step - loss: 0.5330 - accuracy: 0.7385\n",
      "Epoch 60/100\n",
      "858/858 [==============================] - 4s 5ms/step - loss: 0.5336 - accuracy: 0.7398\n",
      "Epoch 61/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5343 - accuracy: 0.7391\n",
      "Epoch 62/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5333 - accuracy: 0.7394\n",
      "Epoch 63/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5326 - accuracy: 0.7389\n",
      "Epoch 64/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5332 - accuracy: 0.7391\n",
      "Epoch 65/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5336 - accuracy: 0.7391\n",
      "Epoch 66/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5324 - accuracy: 0.7403\n",
      "Epoch 67/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5323 - accuracy: 0.7403\n",
      "Epoch 68/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5332 - accuracy: 0.7394\n",
      "Epoch 69/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5322 - accuracy: 0.7402\n",
      "Epoch 70/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5320 - accuracy: 0.7402\n",
      "Epoch 71/100\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5326 - accuracy: 0.7403\n",
      "Epoch 72/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5326 - accuracy: 0.7394\n",
      "Epoch 73/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5327 - accuracy: 0.7404\n",
      "Epoch 74/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5325 - accuracy: 0.7408\n",
      "Epoch 75/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5320 - accuracy: 0.7393\n",
      "Epoch 76/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5322 - accuracy: 0.7409\n",
      "Epoch 77/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5320 - accuracy: 0.7398\n",
      "Epoch 78/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5333 - accuracy: 0.7403\n",
      "Epoch 79/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5325 - accuracy: 0.7401\n",
      "Epoch 80/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5313 - accuracy: 0.7402\n",
      "Epoch 81/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5317 - accuracy: 0.7408\n",
      "Epoch 82/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5319 - accuracy: 0.7396\n",
      "Epoch 83/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5316 - accuracy: 0.7416\n",
      "Epoch 84/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5327 - accuracy: 0.7398\n",
      "Epoch 85/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5324 - accuracy: 0.7397\n",
      "Epoch 86/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5315 - accuracy: 0.7408\n",
      "Epoch 87/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5315 - accuracy: 0.7405\n",
      "Epoch 88/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5320 - accuracy: 0.7404\n",
      "Epoch 89/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5325 - accuracy: 0.7399\n",
      "Epoch 90/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5319 - accuracy: 0.7389\n",
      "Epoch 91/100\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.7403\n",
      "Epoch 92/100\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.7408\n",
      "Epoch 93/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5316 - accuracy: 0.7406\n",
      "Epoch 94/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5316 - accuracy: 0.7406\n",
      "Epoch 95/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5316 - accuracy: 0.7402\n",
      "Epoch 96/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5334 - accuracy: 0.7394\n",
      "Epoch 97/100\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5310 - accuracy: 0.7406\n",
      "Epoch 98/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5315 - accuracy: 0.7401\n",
      "Epoch 99/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5307 - accuracy: 0.7411\n",
      "Epoch 100/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5316 - accuracy: 0.7398\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model_3 = nn_3.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 1s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.66      0.69      3196\n",
      "           1       0.73      0.78      0.75      3664\n",
      "\n",
      "    accuracy                           0.72      6860\n",
      "   macro avg       0.72      0.72      0.72      6860\n",
      "weighted avg       0.72      0.72      0.72      6860\n",
      "\n",
      "215/215 - 1s - loss: 0.6307 - accuracy: 0.7235 - 513ms/epoch - 2ms/step\n",
      "Loss: 0.6306723356246948, Accuracy: 0.7234693765640259\n"
     ]
    }
   ],
   "source": [
    "# Get classification_report\n",
    "y_pred_prob_3 = nn_3.predict(X_test_scaled)\n",
    "y_pred_3 = (y_pred_prob_3 > 0.5).astype(int)  \n",
    "print(classification_report(y_test, y_pred_3))\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_3.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn_3.save(\"AlphabetSoupCharity_OptimizationAttempt3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model Optimization Report\n",
    "\n",
    "---\n",
    "## Overview of the Analysis\n",
    "The purpose of this model analysis report is to outline the reasoning used in the optimization of the to predicting successful campaigns at a 75% or higher accuracy. I used a csv file containing data for more than 34,000 organizations that received funding from the nonprofit foundation Alphabet Soup.\n",
    "\n",
    "---\n",
    "## Results\n",
    "\n",
    "---\n",
    "### Data Preprocessing\n",
    "\n",
    "- **Target Variable:** This model is trying to predict successful campaigns by using the `IS_SUCCESSFUL` column found in the dataset, which indicates whether an applicant was successful or not.\n",
    "    \n",
    "- **Feature Variables:** The feature variables are all other columns in the pandas DataFrame after removing the required non-variable columns. These features include various applicant attributes such as `APPLICATION_TYPE`, `ASK_AMT`, `CLASSIFICATION`, and `INCOME_AMT`.\n",
    "    \n",
    "- **Removed Variables:** Based on the value counts of all columns in the dataset, I was able to identify and remove the non-useful identification columns and remove them from the DataFrame. In the end, only the columns `EIN` and `NAME`.\n",
    "  \n",
    "---\n",
    "### Compiling, Training, and Evaluating the Model\n",
    "\n",
    "- **Neurons, Layers, and Activation Functions:**\n",
    "    \n",
    "    - When I initially ran the model, there was only a basic architecture with three layers. However, when optimizing the model, additional layers and neurons were added to enhance model performance.\n",
    "        \n",
    "    - The activation functions used included ReLU for hidden layers and sigmoid for the output layer to handle the binary classification problem. ReLU was chosen to introduce non-linearity and mitigate vanishing gradients, while sigmoid was used for its probabilistic output, aligning with the classification task. Furthermore, I stuck to using the `adam` optimizer when building my models. \n",
    "      \n",
    "- **Model Performance:**\n",
    "    \n",
    "    - The initial model did not achieve the desired accuracy. Multiple different approaches were taken in hopes of increasing the prediction accuracy of the model. iterations of feature selection, data balancing, and architectural changes were made in an attempt to improve performance.\n",
    "      \n",
    "- **Optimization Attempts:**\n",
    "    \n",
    "\t1. **Adding Additional Neural Network Layers and Node on top of Feature Selection:** I ran a random forest model on to predict the `IS_SUCCESSFUL` target. I then used [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to cross validate the models. After doing that, I trained the best-performing model and evaluated the accuracy score. Then, I analyzed which features influenced predictions the most. I then removed low-importance features in an attempt to reduce excessive noise in the dataset. I classified low-importance features as those that contributed less than .05% to the model training. \n",
    "        \n",
    "    2. **SMOTE Oversampling:** Due to the slight imbalance of the target classes, I tried to implement a over-sampling technique to see if that improved the model's accuracy. I used [SMOTE](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html) to balance the target variable distribution, but this did not significantly improve accuracy. Since SMOTE did not yield meaningful performance gains, it was removed in subsequent model refinements to simplify preprocessing.\n",
    "        \n",
    "    3. **ASK_AMT Binarization:** Due to **extreme** imbalance in `ASK_AMT` where the value 5000 was the only instance of a value count over 5, the column was converted into a binary feature where values were either 5000 or other. The model was then retrained without SMOTE, but accuracy improvements remained marginal. \n",
    "      \n",
    "---\n",
    "## Summary\n",
    "\n",
    "---\n",
    "Despite multiple optimization attempts, including feature selection, oversampling, and feature engineering, the final model did not achieve the target accuracy. The transformation of `ASK_AMT` into a binary variable did not yield significant improvement, and SMOTE failed to enhance performance. Given that SMOTE did not contribute to model improvement, it was removed from later iterations to focus on other optimization strategies.\n",
    "\n",
    "**Recommendation:** Given the large class imbalances in several features, replacing the neural network with a Random Forest classifier could yield better results. Random Forests can handle imbalanced data more effectively by adjusting class weights. This approach can improve classification performance without the need for artificial data balancing techniques like SMOTE, which did not provide meaningful gains in accuracy.\n",
    "\n",
    "----\n",
    "## Citations\n",
    "\n",
    "---\n",
    "\n",
    "1. I used [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) in association with [ChatGPT](https://chatgpt.com/) to cross validate the random forest model. This allowed me to find the optimal model and find out the features that most influenced the model's predictions. \n",
    "2. I used [SMOTE](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html) in association with [ChatGPT](https://chatgpt.com/) to over-sample my imbalanced target variable in an attempt to improve model accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
